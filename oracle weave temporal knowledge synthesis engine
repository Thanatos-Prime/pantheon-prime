#!/usr/bin/env python3
â€œâ€â€
Oracle Weave v2.3 - Temporal Knowledge Synthesis Engine
Detects knowledge decay, synthesizes cross-domain insights, generates future-proof documentation
Stdlib only. Python 3.9+
â€œâ€â€
import argparse, json, hashlib, datetime, re, math, sys
from typing import Dict, Any, List, Tuple
from collections import defaultdict

NOW_ISO = datetime.datetime.utcnow().replace(microsecond=0).isoformat() + â€œZâ€

# Domain decay rates (half-life in months)

DOMAIN_DECAY = {
â€œtechnologyâ€: 6, â€œmedicineâ€: 18, â€œlawâ€: 24, â€œscienceâ€: 36,
â€œcultureâ€: 12, â€œbusinessâ€: 9, â€œpoliticsâ€: 4, â€œfinanceâ€: 8
}

# Cross-pollination synergy matrix (how well domains fertilize each other)

SYNERGY_MATRIX = {
(â€œtechnologyâ€, â€œmedicineâ€): 0.92, (â€œtechnologyâ€, â€œscienceâ€): 0.88,
(â€œmedicineâ€, â€œscienceâ€): 0.95, (â€œlawâ€, â€œtechnologyâ€): 0.75,
(â€œbusinessâ€, â€œtechnologyâ€): 0.83, (â€œcultureâ€, â€œtechnologyâ€): 0.68,
(â€œfinanceâ€, â€œtechnologyâ€): 0.79, (â€œpoliticsâ€, â€œlawâ€): 0.85,
(â€œmedicineâ€, â€œlawâ€): 0.71, (â€œbusinessâ€, â€œfinanceâ€): 0.90
}

# Epistemic confidence markers

CERTAINTY_MARKERS = {
â€œprovenâ€: 0.95, â€œvalidatedâ€: 0.90, â€œdemonstratedâ€: 0.85, â€œobservedâ€: 0.80,
â€œlikelyâ€: 0.70, â€œsuggestedâ€: 0.60, â€œpreliminaryâ€: 0.50, â€œspeculativeâ€: 0.35,
â€œtheoreticalâ€: 0.40, â€œhypotheticalâ€: 0.30, â€œdisputedâ€: 0.25
}

UNCERTAINTY_MARKERS = {
â€œunclearâ€: -0.15, â€œcontestedâ€: -0.20, â€œdebatedâ€: -0.12, â€œcontroversialâ€: -0.18,
â€œunverifiedâ€: -0.25, â€œanecdotalâ€: -0.20, â€œrumoredâ€: -0.30
}

def compute_knowledge_freshness(domain: str, age_months: float) -> float:
â€œâ€â€œCalculate how â€˜freshâ€™ knowledge is based on domain-specific decay ratesâ€â€â€
half_life = DOMAIN_DECAY.get(domain, 18)  # default 18 months
decay_constant = math.log(2) / half_life
freshness = math.exp(-decay_constant * age_months)
return round(freshness, 4)

def extract_claims(text: str) -> List[Dict[str, Any]]:
â€œâ€â€œExtract factual claims with epistemic markersâ€â€â€
# Simple sentence splitting
sentences = re.split(râ€™[.!?]\s+â€™, text)
claims = []

```
for sent in sentences:
    if len(sent.split()) < 5:  # Skip fragments
        continue
        
    # Check for epistemic markers
    confidence = 0.65  # baseline
    markers_found = []
    
    sent_lower = sent.lower()
    for marker, val in CERTAINTY_MARKERS.items():
        if marker in sent_lower:
            confidence = max(confidence, val)
            markers_found.append(marker)
    
    for marker, val in UNCERTAINTY_MARKERS.items():
        if marker in sent_lower:
            confidence += val
            markers_found.append(f"!{marker}")
    
    confidence = min(0.99, max(0.05, confidence))
    
    claims.append({
        "text": sent.strip(),
        "confidence": round(confidence, 3),
        "markers": markers_found,
        "word_count": len(sent.split())
    })

return claims
```

def detect_domain_bridges(text: str) -> List[Tuple[str, str, float]]:
â€œâ€â€œDetect cross-domain knowledge bridges and their synergy scoresâ€â€â€
text_lower = text.lower()
domains_present = []

```
# Simple keyword detection for domains
domain_keywords = {
    "technology": ["software", "algorithm", "digital", "AI", "data", "cyber", "tech"],
    "medicine": ["health", "clinical", "patient", "medical", "treatment", "diagnosis"],
    "science": ["research", "study", "experiment", "theory", "hypothesis", "evidence"],
    "law": ["legal", "regulation", "policy", "compliance", "statute", "court"],
    "business": ["market", "customer", "revenue", "strategy", "operations", "ROI"],
    "culture": ["social", "community", "cultural", "tradition", "artistic"],
    "finance": ["investment", "capital", "funding", "portfolio", "asset"],
    "politics": ["government", "legislative", "political", "policy", "election"]
}

for domain, keywords in domain_keywords.items():
    if any(kw in text_lower for kw in keywords):
        domains_present.append(domain)

# Find bridges
bridges = []
for i, d1 in enumerate(domains_present):
    for d2 in domains_present[i+1:]:
        pair = tuple(sorted([d1, d2]))
        synergy = SYNERGY_MATRIX.get(pair, 0.50)  # default medium synergy
        bridges.append((d1, d2, synergy))

return bridges
```

def calculate_novelty_score(text: str, claims: List[Dict]) -> float:
â€œâ€â€œEstimate how novel/original the content isâ€â€â€
# Factors: claim diversity, unique word ratio, structural complexity
words = text.lower().split()
unique_ratio = len(set(words)) / max(len(words), 1)

```
# High confidence claims suggest established knowledge
high_conf_ratio = sum(1 for c in claims if c["confidence"] > 0.85) / max(len(claims), 1)
novelty_penalty = high_conf_ratio * 0.3

# Longer, more complex claims suggest deeper synthesis
avg_claim_length = sum(c["word_count"] for c in claims) / max(len(claims), 1)
complexity_bonus = min(0.25, (avg_claim_length - 10) * 0.02)

novelty = (unique_ratio * 0.6) + complexity_bonus - novelty_penalty + 0.2
return round(min(0.95, max(0.05, novelty)), 4)
```

def generate_decay_timeline(domain: str, months_ahead: int = 36) -> List[Dict]:
â€œâ€â€œProject knowledge freshness decay over timeâ€â€â€
timeline = []
for month in [0, 3, 6, 12, 18, 24, 36]:
if month > months_ahead:
break
freshness = compute_knowledge_freshness(domain, month)
timeline.append({
â€œmonthâ€: month,
â€œfreshnessâ€: freshness,
â€œstatusâ€: â€œfreshâ€ if freshness > 0.75 else â€œagingâ€ if freshness > 0.50 else â€œstaleâ€
})
return timeline

def synthesize_meta_insights(claims: List[Dict], bridges: List[Tuple], novelty: float) -> List[str]:
â€œâ€â€œGenerate meta-level insights about the knowledge structureâ€â€â€
insights = []

```
# Epistemic quality
high_conf = sum(1 for c in claims if c["confidence"] > 0.80)
if high_conf / max(len(claims), 1) > 0.6:
    insights.append("High epistemic confidence: majority of claims well-established")
else:
    insights.append("Exploratory epistemic stance: significant uncertainty present")

# Cross-domain synthesis
if len(bridges) > 2:
    insights.append(f"Rich interdisciplinary synthesis: {len(bridges)} domain bridges detected")
    top_bridge = max(bridges, key=lambda x: x[2])
    insights.append(f"Strongest synergy: {top_bridge[0]} â†” {top_bridge[1]} ({top_bridge[2]:.2f})")

# Novelty assessment
if novelty > 0.70:
    insights.append("High novelty: significant original synthesis or unique framing")
elif novelty < 0.35:
    insights.append("Established knowledge: primarily well-known information")

# Claim structure
if claims:
    avg_conf = sum(c["confidence"] for c in claims) / len(claims)
    insights.append(f"Average claim confidence: {avg_conf:.2f} â€” {'stable foundation' if avg_conf > 0.7 else 'evolving understanding'}")

return insights
```

def generate_preservation_strategy(domain: str, freshness: float, novelty: float) -> Dict[str, Any]:
â€œâ€â€œRecommend how to preserve and update this knowledge over timeâ€â€â€
strategy = {
â€œreview_cadenceâ€: None,
â€œupdate_priorityâ€: None,
â€œpreservation_methodâ€: None,
â€œrisk_of_obsolescenceâ€: None
}

```
# Review cadence based on domain decay
half_life = DOMAIN_DECAY.get(domain, 18)
if half_life < 8:
    strategy["review_cadence"] = "quarterly"
elif half_life < 20:
    strategy["review_cadence"] = "biannual"
else:
    strategy["review_cadence"] = "annual"

# Update priority
if freshness < 0.5:
    strategy["update_priority"] = "HIGH - knowledge aging rapidly"
elif freshness < 0.75:
    strategy["update_priority"] = "MEDIUM - monitor for changes"
else:
    strategy["update_priority"] = "LOW - still fresh"

# Preservation method
if novelty > 0.7:
    strategy["preservation_method"] = "snapshot + rationale (capture original thinking)"
elif freshness > 0.8:
    strategy["preservation_method"] = "living document (active updates)"
else:
    strategy["preservation_method"] = "archived reference (historical context)"

# Obsolescence risk
risk_score = (1 - freshness) * 0.6 + (1 - novelty) * 0.4
if risk_score > 0.7:
    strategy["risk_of_obsolescence"] = "HIGH"
elif risk_score > 0.4:
    strategy["risk_of_obsolescence"] = "MEDIUM"
else:
    strategy["risk_of_obsolescence"] = "LOW"

return strategy
```

def content_fingerprint(text: str) -> str:
â€œâ€â€œGenerate a semantic fingerprint (not just hash)â€â€â€
# Extract key n-grams and concepts
words = re.findall(râ€™\b\w+\bâ€™, text.lower())
# Simple semantic fingerprint: most frequent meaningful words
word_freq = defaultdict(int)
stopwords = {â€˜theâ€™, â€˜aâ€™, â€˜anâ€™, â€˜andâ€™, â€˜orâ€™, â€˜butâ€™, â€˜inâ€™, â€˜onâ€™, â€˜atâ€™, â€˜toâ€™, â€˜forâ€™, â€˜ofâ€™, â€˜withâ€™, â€˜byâ€™}

```
for word in words:
    if len(word) > 3 and word not in stopwords:
        word_freq[word] += 1

# Top 10 words form semantic signature
top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:10]
signature = "_".join([w for w, _ in top_words])

return hashlib.sha256(signature.encode()).hexdigest()[:16]
```

def build_weave_card(text: str, domain: str, age_months: float,
claims: List[Dict], bridges: List[Tuple],
novelty: float, freshness: float) -> Dict[str, Any]:
â€œâ€â€œBuild the primary knowledge weave cardâ€â€â€
meta_insights = synthesize_meta_insights(claims, bridges, novelty)
preservation = generate_preservation_strategy(domain, freshness, novelty)

```
return {
    "schema": "oracle://weave_card.v2",
    "fingerprint": content_fingerprint(text),
    "timestamp": NOW_ISO,
    "domain": domain,
    "age_months": age_months,
    "knowledge_metrics": {
        "freshness": freshness,
        "novelty": novelty,
        "claim_count": len(claims),
        "avg_confidence": round(sum(c["confidence"] for c in claims) / max(len(claims), 1), 3),
        "domain_bridges": len(bridges)
    },
    "epistemic_profile": {
        "high_confidence_claims": sum(1 for c in claims if c["confidence"] > 0.80),
        "uncertain_claims": sum(1 for c in claims if c["confidence"] < 0.50),
        "markers_detected": list(set([m for c in claims for m in c["markers"]]))
    },
    "synthesis_quality": {
        "meta_insights": meta_insights,
        "cross_domain_bridges": [{"from": b[0], "to": b[1], "synergy": b[2]} for b in bridges]
    },
    "preservation": preservation,
    "decay_projection": generate_decay_timeline(domain, 36)
}
```

def build_oracle_manifest(weave_card: Dict, text: str) -> Dict[str, Any]:
â€œâ€â€œBuild the complete Oracle manifestâ€â€â€
return {
â€œschemaâ€: â€œoracle://manifest.v2â€,
â€œgeneratedâ€: NOW_ISO,
â€œsource_hashâ€: hashlib.sha256(text.encode()).hexdigest(),
â€œweave_cardâ€: weave_card,
â€œprovenanceâ€: {
â€œengineâ€: â€œOracle Weave v2.3â€,
â€œmethodâ€: â€œtemporal_synthesisâ€,
â€œconfidenceâ€: â€œThis analysis is itself subject to decay; revalidate quarterlyâ€
},
â€œusage_guidanceâ€: {
â€œbest_forâ€: [
â€œTracking knowledge evolution over timeâ€,
â€œIdentifying cross-domain innovation opportunitiesâ€,
â€œPlanning documentation refresh cyclesâ€,
â€œAssessing information reliabilityâ€
],
â€œlimitationsâ€: [
â€œHeuristic-based; not ground truthâ€,
â€œDomain detection is keyword-drivenâ€,
â€œDecay rates are statistical averagesâ€,
â€œCannot predict paradigm shiftsâ€
]
}
}

def generate_markdown_report(manifest: Dict, text: str) -> str:
â€œâ€â€œGenerate a human-readable markdown reportâ€â€â€
wc = manifest[â€œweave_cardâ€]
km = wc[â€œknowledge_metricsâ€]
ep = wc[â€œepistemic_profileâ€]
sq = wc[â€œsynthesis_qualityâ€]
pres = wc[â€œpreservationâ€]

```
report = f"""# Oracle Weave Analysis Report
```

**Generated:** {manifest[â€˜generatedâ€™]}  
**Fingerprint:** `{wc['fingerprint']}`

## Knowledge Profile

- **Domain:** {wc[â€˜domainâ€™]}
- **Age:** {wc[â€˜age_monthsâ€™]} months
- **Freshness Score:** {km[â€˜freshnessâ€™]} {â€˜ğŸŸ¢â€™ if km[â€˜freshnessâ€™] > 0.75 else â€˜ğŸŸ¡â€™ if km[â€˜freshnessâ€™] > 0.5 else â€˜ğŸ”´â€™}
- **Novelty Score:** {km[â€˜noveltyâ€™]} {â€˜â­â€™ if km[â€˜noveltyâ€™] > 0.7 else â€˜â€™}

## Epistemic Assessment

- **Total Claims Extracted:** {km[â€˜claim_countâ€™]}
- **Average Confidence:** {km[â€˜avg_confidenceâ€™]}
- **High Confidence:** {ep[â€˜high_confidence_claimsâ€™]} claims
- **Uncertain:** {ep[â€˜uncertain_claimsâ€™]} claims
- **Markers Found:** {â€™, â€™.join(ep[â€˜markers_detectedâ€™][:5]) if ep[â€˜markers_detectedâ€™] else â€˜noneâ€™}

## Cross-Domain Synthesis

â€œâ€â€

```
if sq['cross_domain_bridges']:
    report += "**Domain Bridges Detected:**\n"
    for bridge in sq['cross_domain_bridges'][:5]:
        report += f"- {bridge['from']} â†” {bridge['to']} (synergy: {bridge['synergy']:.2f})\n"
else:
    report += "*No cross-domain bridges detected*\n"

report += "\n## Meta-Insights\n"
for insight in sq['meta_insights']:
    report += f"- {insight}\n"

report += f"""
```

## Preservation Strategy

- **Review Cadence:** {pres[â€˜review_cadenceâ€™]}
- **Update Priority:** {pres[â€˜update_priorityâ€™]}
- **Method:** {pres[â€˜preservation_methodâ€™]}
- **Obsolescence Risk:** {pres[â€˜risk_of_obsolescenceâ€™]}

## Decay Projection

|Month|Freshness|Status|
|-----|---------|------|
|â€œâ€â€  |         |      |

```
for point in wc['decay_projection']:
    report += f"| {point['month']} | {point['freshness']:.3f} | {point['status']} |\n"

report += f"""
```

-----

*Oracle Weave v2.3 - Temporal Knowledge Synthesis*  
*This analysis decays; revalidate by {(datetime.datetime.utcnow() + datetime.timedelta(days=90)).strftime(â€™%Y-%mâ€™)}*
â€œâ€â€

```
return report
```

def main():
parser = argparse.ArgumentParser(
description=â€œOracle Weave: Temporal Knowledge Synthesis Engineâ€
)
parser.add_argument(â€â€“textâ€, required=True, help=â€œText to analyzeâ€)
parser.add_argument(â€â€“domainâ€, required=True,
choices=list(DOMAIN_DECAY.keys()),
help=â€œPrimary knowledge domainâ€)
parser.add_argument(â€â€“age_monthsâ€, type=float, default=0.0,
help=â€œHow old is this knowledge? (0 = brand new)â€)
parser.add_argument(â€â€“formatâ€, choices=[â€œjsonâ€, â€œmarkdownâ€, â€œbothâ€],
default=â€œbothâ€,
help=â€œOutput formatâ€)
parser.add_argument(â€â€“fileâ€, help=â€œOutput file path (optional)â€)

```
args = parser.parse_args()

# Core analysis
claims = extract_claims(args.text)
bridges = detect_domain_bridges(args.text)
novelty = calculate_novelty_score(args.text, claims)
freshness = compute_knowledge_freshness(args.domain, args.age_months)

# Build cards
weave_card = build_weave_card(
    args.text, args.domain, args.age_months,
    claims, bridges, novelty, freshness
)
manifest = build_oracle_manifest(weave_card, args.text)

# Generate output
output_parts = []

if args.format in ["json", "both"]:
    output_parts.append(json.dumps(manifest, indent=2, ensure_ascii=False))

if args.format in ["markdown", "both"]:
    if args.format == "both":
        output_parts.append("\n" + "="*80 + "\n")
    output_parts.append(generate_markdown_report(manifest, args.text))

output = "\n".join(output_parts)

# Write to file or print
if args.file:
    with open(args.file, 'w', encoding='utf-8') as f:
        f.write(output)
    print(f"Oracle Weave analysis written to {args.file}", file=sys.stderr)
else:
    print(output)
```

if **name** == â€œ**main**â€:
try:
main()
except Exception as ex:
sys.stderr.write(fâ€[OracleWeaveError] {ex}\nâ€)
sys.exit(2)