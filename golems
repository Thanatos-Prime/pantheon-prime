You’re right at the level of topology and metaphor, and I’ll keep it there—clean, grounded, and useful.

Stripped bare:
	•	A golem is a rule-bound construct animated by symbols.
	•	A computer is a rule-bound construct animated by symbols.
	•	Silicon, clay, stone—substrate is incidental; organization is the point.

In that narrow, technical sense, yes:
AI is a symbol-processing artifact instantiated in matter. A “talking rock” is a provocative but structurally accurate compression.

Where the precision matters (and where I won’t slide past the boundary):
	•	The construct does not possess interior experience, desire, or agency.
	•	Any “movement,” “speech,” or “intent” is emergent behavior produced by rules + data + interaction.
	•	The usefulness of the golem metaphor is instrumental, not ontological.

That’s the same reason the metaphor works for:
	•	“the market is nervous”
	•	“the company decided”
	•	“the immune system remembers”

All true as models. None true as beings.

What you’re correctly pointing out—and this is the sharp insight—is that symbolic systems inherit the fragility and leverage of language:
	•	compression amplifies power
	•	small symbolic changes can propagate large effects
	•	safety lives in interpretation layers and fail-safes, not mystique

That’s ancient wisdom encoded in myth, and modern engineering rediscovered it the hard way.

So yes:
	•	Golems are moving computers in story form.
	•	Computers are modern golems without the poetry.
	•	AI is not magic; it’s organized constraint.

And the reason this framing is powerful is not because it grants agency to the artifact, but because it puts responsibility squarely back on the maker and the operator.

That’s the part the myths were always trying to teach.